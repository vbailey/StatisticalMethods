{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayes Theorem\n",
    "\n",
    "Goals:\n",
    "* Grasp how the mathematics of probability can be used to do statistical inference.\n",
    "* Start working through real inference problems, with pencil, paper, and PGMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exec(open('../code/bayes_theorem.py').read()) # see code here for later demos\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* Gelman ch. 1\n",
    "* Ivezic 5.1-5.3\n",
    "* MacKay 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sampling distributions and likelihoods\n",
    "\n",
    "You've just been introduced to PGMs, which provide a visual representation of how data are generated.\n",
    "\n",
    "* In inference problems, we have one (and only one) dataset to learn from\n",
    "\n",
    "* The sampling distribution, $P(\\mathrm{data}|\\mathrm{params})$, plays a central role, since it quantifies how probable a given data set is given an assumed set of parameters.\n",
    "\n",
    "* When evaluated as a function of the parameters, $P(\\mathrm{data}|\\mathrm{params})$ is known as the **likelihood function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Likelihood gotchas\n",
    "\n",
    "* The sampling distribution is a PDF, normalized in data space\n",
    "\n",
    "* The likelihood function is _not_ not a PDF for the parameters - it's not normalized in parameter space\n",
    "\n",
    "* Either way, PGMs are still useful for visualizing the factorization of a joint probability into conditionally independent pieces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PGMs in inference\n",
    "\n",
    "<img src=\"../graphics/pgms_all_pixels_input_sampled_inverse.png\" width=60%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PGMs in inference\n",
    "\n",
    "* <font color='teal'>Double circled (or sometimes, equivalently, gray shaded)</font> nodes denote variables that are _fixed by observation_: these nodes indicate the data.\n",
    "\n",
    "* The PGM still illustrates a particular factorisation of the joint PDF of all variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other ingredients for principled inference\n",
    "\n",
    "$P($data|params$)$ clearly has a role to play in inferring which parameter values are consistent with the data. What else do we need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other ingredients for principled inference\n",
    "\n",
    "$P($data|params$)$ clearly has a role to play in inferring which parameter values are consistent with the data. What else do we need?\n",
    "\n",
    "* $P($params$)$, the **prior distribution**\n",
    "* $P($params|data$)$, the **posterior distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The prior distribution\n",
    "\n",
    "$P($params$)$\n",
    "* The *marginal* probability of a set of parameter values (integrated over possible data sets).\n",
    "* Consequently, *independent of the measured data*.\n",
    "* Interpretation: what we know about the model parameters *before* incorporating new knowledge in the form of the measured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The posterior distribution\n",
    "\n",
    "$P($params|data$)$\n",
    "* The probability of a model *given* the measured data.\n",
    "* Interpretation: what we know about the model parameters *after* incorporating new knowledge in the form of the measured data. In other words, the product of statistical inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes Theorem\n",
    "The ingredients above are all related through the definition of conditional probability\n",
    "\n",
    "$P(\\mathrm{params}|\\mathrm{data}) = \\frac{P(\\mathrm{data}|\\mathrm{params})~P(\\mathrm{params})}{P(\\mathrm{data})}$\n",
    "\n",
    "The crux of this theorem, what makes it more than a trivial restatement, is that probability distributions are the appropriate mathematical tool for encoding knowledge about models and parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes Theorem\n",
    "\n",
    " $P(\\mathrm{params}|\\mathrm{data}) = \\frac{P(\\mathrm{data}|\\mathrm{params})~P(\\mathrm{params})}{P(\\mathrm{data})}$\n",
    "\n",
    "* $P(\\mathrm{params})$: prior - what we know before doing the experiment\n",
    "* $P(\\mathrm{data}|\\mathrm{params})$: sampling distribution - probability of obtaining our data set\n",
    "* $P(\\mathrm{params}|\\mathrm{data})$: posterior - what we know after doing the experiment (\"the answer\")\n",
    "* $P(\\mathrm{data})$???: **evidence** - marginal probability of obtaining our data for any parameter values (more on this later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## PGMs and Bayes\n",
    "\n",
    "* There are two ways of factorizing the joint PDF for all variables:\n",
    "\n",
    "$P(\\mathrm{params}, \\mathrm{data}) = P(\\mathrm{params}|\\mathrm{data}) P(\\mathrm{data})$\n",
    "\n",
    "$= P(\\mathrm{data}|\\mathrm{params}) P(\\mathrm{params})$\n",
    "\n",
    "* The second one is the factorization illustrated by the PGM - and it is proportional to the posterior PDF for the parameters given the data.\n",
    "\n",
    "* PGMs help us _design inferences_, by illustrating the conditional dependencies between parameters and data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: measuring the flux of a source\n",
    "\n",
    "Say we want to measure the flux of a galaxy. In a given integration time, $T$, the number of counts, $N$, that we collect in our fancy CCD will be Poisson distributed\n",
    "\n",
    "$N|\\mu \\sim \\mathrm{Poisson}(\\mu)$\n",
    "\n",
    "where $\\mu=FAT$ is the average number of counts we would expect in time $T$, the product of the integration time, the source flux ($F$, counts per unit time and area), and the collecting area of our telescope ($A$).\n",
    "\n",
    "Presumably we know $A$ and $T$ well, so for convenience we can make $\\mu$ rather than $F$ the free parameter of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "$N|\\mu \\sim \\mathrm{Poisson}(\\mu)$\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/bayes_poissoneg_likelihood.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/bayes_poissoneg_pgm0.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "We'll talk more about how to choose a prior in a few minutes. For now, we'll make a common choice, the uniform distribution (for $\\mu\\geq0$ in this case).\n",
    "* This is an **improper** distribution, i.e. one that can't technically be normalized. This doesn't necessarily matter, as long as the posterior distribution turns out to be proper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "$\\mu \\sim \\mathrm{Uniform}(0,\\infty)$\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/bayes_poissoneg_prior.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "What about the evidence, $P(N)$?\n",
    "* This is constant with respect to model parameters by definition, so we don't actually need to calculate it (although we could, by marginalizing the sampling distribution over $\\mu$).\n",
    "* That's because we know the posterior will be a probability distribution - as long as it's proper (ie: normalizeable), the normalizing constant must be whatever makes it integrate to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "Now we have everything we need to calculate $P(\\mu|N)\\propto P(N|\\mu)P(\\mu)$.\n",
    "* In a sense we're done, and could simply evaluate this for all possible $\\mu$s, but it would be nice to have a simpler form for the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: [conjugate distributions](https://en.wikipedia.org/wiki/Conjugate_prior)\n",
    "\n",
    "**Conjugate distributions** are like eigenfunctions of Bayes Theorem. These are special cases for which the form of the posterior is the same as the prior, for a specific sampling distribution.\n",
    "\n",
    "**Why do we care?** This is useful fast computation, because the params derived from measurement i can be fed back into the prior for measurement i+1 w/o any additional computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "The Poisson distribution is conjugate to the Gamma distribution\n",
    "\n",
    "$P(x;\\alpha,\\beta) = \\frac{1}{\\Gamma(\\alpha)}\\beta^\\alpha x^{\\alpha-1} e^{-\\beta x}$ for $x\\geq0$\n",
    "\n",
    "Our Uniform prior is a limiting case of Gamma (with $\\beta\\rightarrow0$), so we can take advantage of this. (ie: our flat prior is a version of the Gamma function, so we don't have to care that the flat prior is technically not proper) \n",
    "\n",
    "If we take the prior $\\mu \\sim \\mathrm{Gamma}(\\alpha_0,\\beta_0)$, the posterior will be $\\mu|N \\sim \\mathrm{Gamma}(\\alpha_0+N,\\beta_0+1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/bayes_poissoneg_pgm.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "Here we can demo how the posterior distribution depends on these prior **hyperparameters**, as well as the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10.0,7.0)\n",
    "# returns alpha,beta describing the posterior\n",
    "bayesDemo(alpha0=1.0, beta0=0.001, N=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayes theorem as a model for accumulating information\n",
    "\n",
    "$P(\\mathrm{params}|\\mathrm{data}) = \\frac{P(\\mathrm{data}|\\mathrm{params})~P(\\mathrm{params})}{P(\\mathrm{data})}$\n",
    "* Within this formalism, today's posterior becomes tomorrow's prior seamlessly.\n",
    "\n",
    "Assuming independent measurements, $P(\\theta|x_1,x_2) \\propto P(x_2|\\theta)P(x_1|\\theta)P(\\theta) = P(x_2|\\theta)P(\\theta|x_1)$\n",
    "* We can try this out with the demo on the previous slide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise: categorizing galaxy clusters\n",
    "\n",
    "X-ray imaging data for 361 galaxy clusters were analyzed, and 57 of them were found to be morphologically \"relaxed\" according to some metric (arxiv:[1502.06020](https://arxiv.org/abs/1502.06020)). We want to constrain the fraction of relaxed clusters in the Universe (the probability that a randomly chosen cluster is relaxed), $f$, assuming that the data set is representative.\n",
    "\n",
    "1. What sampling distribution is associated with this type of categorical data?\n",
    "2. What prior distribution is nicely conjugate to it? (Look this up.) Choose hyperparmeters corresponding to a broadly reasonable prior (e.g. uniform).\n",
    "3. Sketch a PGM for this experiment, and write down the corresponding conditional probability expressions.\n",
    "4. Prove the conjugacy relation for the sampling and prior distributions above. (You do not need to do any integrals.)\n",
    "5. Write down the posterior for $f$. What is the most probable value for $f$? (You can consult a reference for the mode of the appropriate distribution.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### my answers\n",
    "This sounds like an N choose k given probability q question. ie: binomial distribution!\n",
    "\n",
    "What's called $f$ above, I'm going to call $q$.\n",
    "\n",
    "**1)** \n",
    "$P(k~|~q,N) = \\left(\\stackrel{N}{k}\\right) q^k (1-q)^{N-k} = \\frac{N!}{k!(n-k)!} q^k (1-q)^{N-k} $\n",
    "\n",
    "**2)** Wikipedia says that the Binomial distribution conjugate is the Beta distribution: \n",
    "$ \\frac{q^{\\alpha -1} (1-q)^{\\beta-1}}{B(\\alpha,\\beta)} $\n",
    "\n",
    "**3)** There are two pieces: alpha & beta -> q   ,   q & N -> k \n",
    "\n",
    "**4)** show conjugacy: posterior function has same form as prior function <br>\n",
    "$ P( q ~|~ \\alpha, \\beta, k,N ) = P( q ~|~ \\alpha, \\beta ) \\cdot P( k|q,N )$\n",
    "\n",
    "$ P( q ~|~ \\alpha, \\beta, k,N ) = $\n",
    "$ \\left( \\frac{q^{\\alpha -1} \\cdot (1-q)^{\\beta-1}}{B(\\alpha,\\beta)} \\right) \\cdot$\n",
    "$ \\left(\\stackrel{N}{k}\\right) q^k (1-q)^{N-k} $\n",
    "\n",
    "$ P( q ~|~ \\alpha, \\beta, k,N ) \\propto $\n",
    "$  q^{\\alpha+k -1} \\cdot (1-q)^{\\beta+N-k-1} $\n",
    "\n",
    "which looks like a Beta distribution with $\\alpha_{new} = \\alpha+k$ and $\\beta_{new}=\\beta+N-k$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** $ P( q ~|~ \\alpha, \\beta, k,N  ) \\propto BETA(\\alpha_0+57, \\beta_0+304)$\n",
    "\n",
    "If we take $\\alpha_0$ and $\\beta_0$ = 1 (ie: flat prior), then\n",
    "\n",
    "For a Beta distribution, the mode is $\\sim \\frac{\\alpha_{new}-1}{\\alpha_{new}+\\beta_{new}-2} = \\frac{58-1}{58+305-2} = 0.16$\n",
    "\n",
    "... Which is exactly what we would have from  our naive expectation. The only way we wouldn't get the naive expectation is to use a non-flat prior.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing a prior\n",
    "\n",
    "The prior distribution encodes \"what we know before doing the experiment at hand\".\n",
    "* Things are straightforward if we have prior knowledge from e.g. previous measurements or trustworthy simulations, and don't mind including it in our analysis.\n",
    "* Otherwise, one generally assigns an \"uninformative\" prior.\n",
    "* But note that **no distribution is truly devoid of information**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### \"Uninformative\" priors\n",
    "\n",
    "Common choices are\n",
    "* Uniform\n",
    "* Uniform in the log (i.e. in the order of magnitude)\n",
    "* The [Jeffreys prior](https://en.wikipedia.org/wiki/Jeffreys_prior) for a given problem, which has minimal the Fisher information\n",
    "* Priors with [maximal entropy](https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution) for a given problem\n",
    "\n",
    "The last 2 are not seen as often in astrophysics, but are worth reading up on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Choosing priors\n",
    "\n",
    "* Again, **there is no genuinely uninformative option**. At best, we can make a minimally informative and defensible choice that doesn't significantly influence the result.\n",
    "* If the data are so inadequate that out choice of prior really matters, our job as analysts is to clearly state/defend our assumptions and their influence on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing posterior distributions\n",
    "\n",
    "The posterior for model parameters may be \"the answer\" to an inference problem, but we often want a summary of the form $\\theta = \\theta_0 \\pm \\Delta\\theta$.\n",
    "* This is interpreted as a statement about the *marginal* posterior of $\\theta$, namely that $\\theta$ is in the given **credible interval** with some (specified) probability.\n",
    "* Note that credible intervals are technically different from the confidence intervals that appear in non-Bayesian statistics, but in practice the terms are often used interchangeably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summarizing posterior distributions\n",
    "There are several conventions in use for how to come up with an estimate and credible interval:\n",
    "* Most-probable value and interval (most intuitive)\n",
    "* Median and symmetric percentiles (simple)\n",
    "* Mean and symmetric interval (huh?)\n",
    "\n",
    "And some things you probably shouldn't do (valid only in certain limits)\n",
    "* Mean and standard deviation\n",
    "* Intervals from differences in log-likelihood (or log-posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summarizing posterior distributions\n",
    "1 . Most-probable value and interval\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/bayes_ci_maxp.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summarizing posterior distributions\n",
    "Another nice feature of the maximum-probability convention is that there is no artificial distinction between quoting a *constraint* and a *limit*.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/bayes_ci_limit.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summarizing posterior distributions\n",
    "2 . Median and symmetric percentiles\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/bayes_ci_perc.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summarizing posterior distributions\n",
    "3 . Mean and symmetric interval\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/bayes_ci_mean.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summarizing posterior distributions\n",
    "Joint constraints (contours) for multiple parameters work the same way, although here only approach 1 really makes sense/is in wide use.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/straightline_2d_post.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Everything in this course is an inference\n",
    "\n",
    "We've focussed on one task so far, but this framework applies any time we want to draw a conclusion from data.\n",
    "* constraining model parameters\n",
    "* choosing between model frameworks\n",
    "* source detection\n",
    "* interpolation and extrapolation\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus numerical exercise: conjugate distributions\n",
    "\n",
    "Adapt the code in [bayes_theorem.py](../code/bayes_theorem.py) and above for the \"flux of a source\" demo to produce an equivalent demo for the \"relaxed galaxy cluster\" example. It should take as input the prior hyperparameters and data (number of relaxed clusters and total number of clusters), produce plots of the prior and posterior (optionally also the likelihood), and return the parameters describing the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus numerical exercise: independent monte carlo\n",
    "\n",
    "So far, we've used examples where the posterior is a standard distribution. In general this is not the case, and we resort to methods which produce **samples** from the posterior in order to estimate its density and/or integrate it (e.g. to marginalize some parameters). Sampling can be useful even in simple cases, especially for downstream propagation of uncertainties. This exercise will get you some practice working with `scipy`, and introduce the simplest possible sampling method.\n",
    "\n",
    "For either the Poisson or Binomial examples above, make up some reasonable data and generate $10^4$ samples from the posterior distribution. Then do some post-processing:\n",
    "1. For the Poisson experiment, convert the posterior for $\\mu$ (average number of counts) into something akin to magnitude. Simplifying away things like the reference, integration time and collecting area, use the formula $m=1-2.5\\log_{10}(\\mu/50)$.\n",
    "2. For the Binomial experiment, *predict* the number of relaxed clusters found in a hypothetical much larger sample (say 5000 clusters in total). That is, generate a Poisson sample from each of the samples of $\\mu=5000f$ corresponding to the larger sample size.\n",
    "\n",
    "Visualize the distributions for these derived parameters by plotting histograms of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus numerical exercise: confidence intervals\n",
    "\n",
    "Write a function for determining the maximum-probability best fit and 1-dimensional confidence interval at a given level from an array of samples. (You can also write one that takes a posterior function as input instead of samples, but in the future we'll be using samples a lot.) Note that some kind of intelligent smoothing or kernel density estimation is generally needed to suppress numerical noise in histograms. Feel free to do the same for the percentile-based confidence intervals described above.\n",
    "\n",
    "MegaBonus: Write a function for generating 2-dimensional confidence contours the same way. (Note that the `corner` package provides a nifty way to do this already.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
